Jul 22 02:38:42 mg-cluster-worker3 systemd[1]: kubelet.service - kubelet: The Kubernetes Node Agent was skipped because of an unmet condition check (ConditionPathExists=/var/lib/kubelet/config.yaml).
Jul 22 02:39:12 mg-cluster-worker3 systemd[1]: Starting kubelet.service - kubelet: The Kubernetes Node Agent...
Jul 22 02:39:12 mg-cluster-worker3 systemd[1]: Started kubelet.service - kubelet: The Kubernetes Node Agent.
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.007658     175 server.go:205] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.317955     175 server.go:484] "Kubelet version" kubeletVersion="v1.30.0"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.317980     175 server.go:486] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.318108     175 server.go:927] "Client rotation is on, will bootstrap in background"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.319822     175 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334606     175 server.go:810] "NoSwap is set due to memorySwapBehavior not specified" memorySwapBehavior="" FailSwapOn=false
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334733     175 container_manager_linux.go:265] "Container manager verified user specified cgroup-root exists" cgroupRoot=["kubelet"]
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334758     175 container_manager_linux.go:270] "Creating Container Manager object based on Node Config" nodeConfig={"NodeName":"mg-cluster-worker3","RuntimeCgroupsName":"/system.slice/containerd.service","SystemCgroupsName":"","KubeletCgroupsName":"","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/kubelet","CgroupDriver":"systemd","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null}
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334840     175 topology_manager.go:138] "Creating topology manager with none policy"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334847     175 container_manager_linux.go:301] "Creating device plugin manager"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334905     175 state_mem.go:36] "Initialized new in-memory state store"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334955     175 kubelet.go:400] "Attempting to sync node with API server"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334982     175 kubelet.go:301] "Adding static pod path" path="/etc/kubernetes/manifests"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.334994     175 kubelet.go:312] "Adding apiserver pod source"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.335000     175 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.336944     175 kuberuntime_manager.go:261] "Container runtime initialized" containerRuntime="containerd" version="v1.7.15" apiVersion="v1"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.338129     175 kubelet.go:815] "Not starting ClusterTrustBundle informer because we are in static kubelet mode"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: W0722 02:39:13.338197     175 probe.go:272] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.340100     175 server.go:1264] "Started kubelet"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.341133     175 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.349913     175 volume_manager.go:291] "Starting Kubelet Volume Manager"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.341831     175 server.go:163] "Starting to listen" address="0.0.0.0" port=10250
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.350801     175 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: W0722 02:39:13.347732     175 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.350926     175 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: W0722 02:39:13.347773     175 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: nodes "mg-cluster-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.350982     175 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: nodes "mg-cluster-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.351021     175 desired_state_of_world_populator.go:149] "Desired state populator starts to run"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.352241     175 factory.go:221] Registration of the systemd container factory successfully
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.352294     175 factory.go:219] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.341850     175 ratelimit.go:55] "Setting rate limiting for endpoint" service="podresources" qps=100 burstTokens=10
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.347667     175 event.go:359] "Server rejected event (will not retry!)" err="events is forbidden: User \"system:anonymous\" cannot create resource \"events\" in API group \"\" in the namespace \"default\"" event="&Event{ObjectMeta:{mg-cluster-worker3.17e468968a7b48d9  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:mg-cluster-worker3,UID:mg-cluster-worker3,APIVersion:,ResourceVersion:,FieldPath:,},Reason:Starting,Message:Starting kubelet.,Source:EventSource{Component:kubelet,Host:mg-cluster-worker3,},FirstTimestamp:2024-07-22 02:39:13.340090585 +0000 UTC m=+0.374379418,LastTimestamp:2024-07-22 02:39:13.340090585 +0000 UTC m=+0.374379418,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:mg-cluster-worker3,}"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.352851     175 server.go:227] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.353039     175 factory.go:221] Registration of the containerd container factory successfully
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.356924     175 server.go:455] "Adding debug handlers to kubelet server"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.351172     175 reconciler.go:26] "Reconciler: start to sync state"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.360996     175 cpu_manager.go:214] "Starting CPU manager" policy="none"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.361015     175 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.361026     175 state_mem.go:36] "Initialized new in-memory state store"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.362331     175 policy_none.go:49] "None policy: Start"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.362853     175 memory_manager.go:170] "Starting memorymanager" policy="None"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.362967     175 state_mem.go:35] "Initializing new in-memory state store"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.375484     175 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.376996     175 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.377021     175 status_manager.go:217] "Starting to sync pod status with apiserver"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: I0722 02:39:13.377032     175 kubelet.go:2337] "Starting kubelet main sync loop"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.377066     175 kubelet.go:2361] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.377872     175 event.go:359] "Server rejected event (will not retry!)" err="events is forbidden: User \"system:anonymous\" cannot create resource \"events\" in API group \"\" in the namespace \"default\"" event="&Event{ObjectMeta:{mg-cluster-worker3.17e468968bb01859  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:mg-cluster-worker3,UID:mg-cluster-worker3,APIVersion:,ResourceVersion:,FieldPath:,},Reason:NodeHasSufficientMemory,Message:Node mg-cluster-worker3 status is now: NodeHasSufficientMemory,Source:EventSource{Component:kubelet,Host:mg-cluster-worker3,},FirstTimestamp:2024-07-22 02:39:13.360328793 +0000 UTC m=+0.394617668,LastTimestamp:2024-07-22 02:39:13.360328793 +0000 UTC m=+0.394617668,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:mg-cluster-worker3,}"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: W0722 02:39:13.378111     175 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.378151     175 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.378222     175 controller.go:145] "Failed to ensure lease exists, will retry" err="leases.coordination.k8s.io \"mg-cluster-worker3\" is forbidden: User \"system:anonymous\" cannot get resource \"leases\" in API group \"coordination.k8s.io\" in the namespace \"kube-node-lease\"" interval="200ms"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.385973     175 event.go:359] "Server rejected event (will not retry!)" err="events is forbidden: User \"system:anonymous\" cannot create resource \"events\" in API group \"\" in the namespace \"default\"" event="&Event{ObjectMeta:{mg-cluster-worker3.17e468968bb02247  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:mg-cluster-worker3,UID:mg-cluster-worker3,APIVersion:,ResourceVersion:,FieldPath:,},Reason:NodeHasNoDiskPressure,Message:Node mg-cluster-worker3 status is now: NodeHasNoDiskPressure,Source:EventSource{Component:kubelet,Host:mg-cluster-worker3,},FirstTimestamp:2024-07-22 02:39:13.360331335 +0000 UTC m=+0.394620168,LastTimestamp:2024-07-22 02:39:13.360331335 +0000 UTC m=+0.394620168,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:mg-cluster-worker3,}"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: W0722 02:39:13.386292     175 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.386332     175 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.387645     175 event.go:359] "Server rejected event (will not retry!)" err="events is forbidden: User \"system:anonymous\" cannot create resource \"events\" in API group \"\" in the namespace \"default\"" event="&Event{ObjectMeta:{mg-cluster-worker3.17e468968bb02a94  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:mg-cluster-worker3,UID:mg-cluster-worker3,APIVersion:,ResourceVersion:,FieldPath:,},Reason:NodeHasSufficientPID,Message:Node mg-cluster-worker3 status is now: NodeHasSufficientPID,Source:EventSource{Component:kubelet,Host:mg-cluster-worker3,},FirstTimestamp:2024-07-22 02:39:13.36033346 +0000 UTC m=+0.394622293,LastTimestamp:2024-07-22 02:39:13.36033346 +0000 UTC m=+0.394622293,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:mg-cluster-worker3,}"
Jul 22 02:39:13 mg-cluster-worker3 kubelet[175]: E0722 02:39:13.388063     175 kubelet.go:1547] "Failed to start ContainerManager" err="failed to initialize top level QOS containers: root container [kubelet kubepods] doesn't exist"
Jul 22 02:39:13 mg-cluster-worker3 systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jul 22 02:39:13 mg-cluster-worker3 systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jul 22 02:39:14 mg-cluster-worker3 systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.
Jul 22 02:39:14 mg-cluster-worker3 systemd[1]: Stopped kubelet.service - kubelet: The Kubernetes Node Agent.
Jul 22 02:39:14 mg-cluster-worker3 systemd[1]: Starting kubelet.service - kubelet: The Kubernetes Node Agent...
Jul 22 02:39:14 mg-cluster-worker3 systemd[1]: Started kubelet.service - kubelet: The Kubernetes Node Agent.
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.509156     214 server.go:205] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.511877     214 server.go:484] "Kubelet version" kubeletVersion="v1.30.0"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.511904     214 server.go:486] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.512024     214 server.go:927] "Client rotation is on, will bootstrap in background"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.512336     214 bootstrap.go:241] unable to read existing bootstrap client config from /etc/kubernetes/kubelet.conf: invalid configuration: [unable to read client-cert /var/lib/kubelet/pki/kubelet-client-current.pem for default-auth due to open /var/lib/kubelet/pki/kubelet-client-current.pem: no such file or directory, unable to read client-key /var/lib/kubelet/pki/kubelet-client-current.pem for default-auth due to open /var/lib/kubelet/pki/kubelet-client-current.pem: no such file or directory]
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.516237     214 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.522047     214 server.go:810] "NoSwap is set due to memorySwapBehavior not specified" memorySwapBehavior="" FailSwapOn=false
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.522203     214 container_manager_linux.go:265] "Container manager verified user specified cgroup-root exists" cgroupRoot=["kubelet"]
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.522242     214 container_manager_linux.go:270] "Creating Container Manager object based on Node Config" nodeConfig={"NodeName":"mg-cluster-worker3","RuntimeCgroupsName":"/system.slice/containerd.service","SystemCgroupsName":"","KubeletCgroupsName":"","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/kubelet","CgroupDriver":"systemd","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null}
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.522369     214 topology_manager.go:138] "Creating topology manager with none policy"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.522395     214 container_manager_linux.go:301] "Creating device plugin manager"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.522438     214 state_mem.go:36] "Initialized new in-memory state store"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.522510     214 kubelet.go:400] "Attempting to sync node with API server"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.522540     214 kubelet.go:301] "Adding static pod path" path="/etc/kubernetes/manifests"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.523458     214 kubelet.go:312] "Adding apiserver pod source"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.523491     214 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.524795     214 kuberuntime_manager.go:261] "Container runtime initialized" containerRuntime="containerd" version="v1.7.15" apiVersion="v1"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.525842     214 kubelet.go:815] "Not starting ClusterTrustBundle informer because we are in static kubelet mode"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.526106     214 server.go:1264] "Started kubelet"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.526709     214 ratelimit.go:55] "Setting rate limiting for endpoint" service="podresources" qps=100 burstTokens=10
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.526898     214 server.go:227] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.527658     214 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.529881     214 event.go:359] "Server rejected event (will not retry!)" err="events is forbidden: User \"system:anonymous\" cannot create resource \"events\" in API group \"\" in the namespace \"default\"" event="&Event{ObjectMeta:{mg-cluster-worker3.17e46896d12c5034  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:mg-cluster-worker3,UID:mg-cluster-worker3,APIVersion:,ResourceVersion:,FieldPath:,},Reason:Starting,Message:Starting kubelet.,Source:EventSource{Component:kubelet,Host:mg-cluster-worker3,},FirstTimestamp:2024-07-22 02:39:14.52609746 +0000 UTC m=+0.046693418,LastTimestamp:2024-07-22 02:39:14.52609746 +0000 UTC m=+0.046693418,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:mg-cluster-worker3,}"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: W0722 02:39:14.530085     214 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: nodes "mg-cluster-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.530262     214 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: nodes "mg-cluster-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: W0722 02:39:14.530366     214 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.530399     214 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.530816     214 server.go:163] "Starting to listen" address="0.0.0.0" port=10250
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.533679     214 server.go:455] "Adding debug handlers to kubelet server"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.535155     214 volume_manager.go:291] "Starting Kubelet Volume Manager"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.535282     214 desired_state_of_world_populator.go:149] "Desired state populator starts to run"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.535345     214 reconciler.go:26] "Reconciler: start to sync state"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.536057     214 factory.go:221] Registration of the systemd container factory successfully
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.536266     214 factory.go:219] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: W0722 02:39:14.536735     214 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.536918     214 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.540709     214 factory.go:221] Registration of the containerd container factory successfully
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.542974     214 controller.go:145] "Failed to ensure lease exists, will retry" err="leases.coordination.k8s.io \"mg-cluster-worker3\" is forbidden: User \"system:anonymous\" cannot get resource \"leases\" in API group \"coordination.k8s.io\" in the namespace \"kube-node-lease\"" interval="200ms"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.547782     214 cpu_manager.go:214] "Starting CPU manager" policy="none"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.550061     214 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.551505     214 state_mem.go:36] "Initialized new in-memory state store"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.551825     214 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.552298     214 state_mem.go:96] "Updated CPUSet assignments" assignments={}
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.552351     214 policy_none.go:49] "None policy: Start"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.554904     214 memory_manager.go:170] "Starting memorymanager" policy="None"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.554951     214 state_mem.go:35] "Initializing new in-memory state store"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.555290     214 state_mem.go:75] "Updated machine memory state"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.568857     214 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.571036     214 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.571102     214 status_manager.go:217] "Starting to sync pod status with apiserver"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.571136     214 kubelet.go:2337] "Starting kubelet main sync loop"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.571173     214 kubelet.go:2361] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.575129     214 manager.go:479] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.575263     214 container_log_manager.go:186] "Initializing container log rotate workers" workers=1 monitorPeriod="10s"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.575420     214 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.576584     214 eviction_manager.go:282] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"mg-cluster-worker3\" not found"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.636050     214 kubelet_node_status.go:73] "Attempting to register node" node="mg-cluster-worker3"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: I0722 02:39:14.639957     214 kubelet_node_status.go:76] "Successfully registered node" node="mg-cluster-worker3"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.648107     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.748840     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.849601     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:14 mg-cluster-worker3 kubelet[214]: E0722 02:39:14.950348     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: E0722 02:39:15.051088     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: E0722 02:39:15.152186     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: E0722 02:39:15.252967     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: E0722 02:39:15.354080     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: E0722 02:39:15.455132     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: I0722 02:39:15.516657     214 transport.go:147] "Certificate rotation detected, shutting down client connections to start using new credentials"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: W0722 02:39:15.516839     214 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.RuntimeClass ended with: very short watch: k8s.io/client-go/informers/factory.go:160: Unexpected watch close - watch lasted less than a second and no items received
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: E0722 02:39:15.556164     214 kubelet_node_status.go:462] "Error getting the current node from lister" err="node \"mg-cluster-worker3\" not found"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: I0722 02:39:15.657331     214 kuberuntime_manager.go:1523] "Updating runtime config through cri with podcidr" CIDR="10.244.1.0/24"
Jul 22 02:39:15 mg-cluster-worker3 kubelet[214]: I0722 02:39:15.658825     214 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.1.0/24"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.526045     214 apiserver.go:52] "Watching apiserver"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.527136     214 topology_manager.go:215] "Topology Admit Handler" podUID="07e6c89b-db2e-4c86-9783-81e58fa48b46" podNamespace="kube-system" podName="kindnet-gc29f"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.527235     214 topology_manager.go:215] "Topology Admit Handler" podUID="0d9e7063-11ed-4f5b-ba60-305c9221d608" podNamespace="kube-system" podName="kube-proxy-p4szr"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.535833     214 desired_state_of_world_populator.go:157] "Finished populating initial desired state of world"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.548174     214 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/0d9e7063-11ed-4f5b-ba60-305c9221d608-lib-modules\") pod \"kube-proxy-p4szr\" (UID: \"0d9e7063-11ed-4f5b-ba60-305c9221d608\") " pod="kube-system/kube-proxy-p4szr"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.548277     214 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-stxb9\" (UniqueName: \"kubernetes.io/projected/0d9e7063-11ed-4f5b-ba60-305c9221d608-kube-api-access-stxb9\") pod \"kube-proxy-p4szr\" (UID: \"0d9e7063-11ed-4f5b-ba60-305c9221d608\") " pod="kube-system/kube-proxy-p4szr"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.548321     214 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-cfg\" (UniqueName: \"kubernetes.io/host-path/07e6c89b-db2e-4c86-9783-81e58fa48b46-cni-cfg\") pod \"kindnet-gc29f\" (UID: \"07e6c89b-db2e-4c86-9783-81e58fa48b46\") " pod="kube-system/kindnet-gc29f"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.548360     214 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/07e6c89b-db2e-4c86-9783-81e58fa48b46-xtables-lock\") pod \"kindnet-gc29f\" (UID: \"07e6c89b-db2e-4c86-9783-81e58fa48b46\") " pod="kube-system/kindnet-gc29f"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.548396     214 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/07e6c89b-db2e-4c86-9783-81e58fa48b46-lib-modules\") pod \"kindnet-gc29f\" (UID: \"07e6c89b-db2e-4c86-9783-81e58fa48b46\") " pod="kube-system/kindnet-gc29f"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.548436     214 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-k9n7f\" (UniqueName: \"kubernetes.io/projected/07e6c89b-db2e-4c86-9783-81e58fa48b46-kube-api-access-k9n7f\") pod \"kindnet-gc29f\" (UID: \"07e6c89b-db2e-4c86-9783-81e58fa48b46\") " pod="kube-system/kindnet-gc29f"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.548467     214 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/0d9e7063-11ed-4f5b-ba60-305c9221d608-kube-proxy\") pod \"kube-proxy-p4szr\" (UID: \"0d9e7063-11ed-4f5b-ba60-305c9221d608\") " pod="kube-system/kube-proxy-p4szr"
Jul 22 02:39:16 mg-cluster-worker3 kubelet[214]: I0722 02:39:16.548509     214 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/0d9e7063-11ed-4f5b-ba60-305c9221d608-xtables-lock\") pod \"kube-proxy-p4szr\" (UID: \"0d9e7063-11ed-4f5b-ba60-305c9221d608\") " pod="kube-system/kube-proxy-p4szr"
Jul 22 02:39:18 mg-cluster-worker3 kubelet[214]: I0722 02:39:18.593962     214 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/kube-proxy-p4szr" podStartSLOduration=4.593950587 podStartE2EDuration="4.593950587s" podCreationTimestamp="2024-07-22 02:39:14 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2024-07-22 02:39:17.592015254 +0000 UTC m=+3.112611211" watchObservedRunningTime="2024-07-22 02:39:18.593950587 +0000 UTC m=+4.114546545"
Jul 22 02:39:18 mg-cluster-worker3 kubelet[214]: I0722 02:39:18.926879     214 kubelet_node_status.go:497] "Fast updating node status as it just became ready"
